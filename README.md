# Reformas-Momento-Ideal

Sistema omnichannel anÃ´nimo (LGPD-safe) para detectar o "momento ideal" de abordagem para reformas, a partir de eventos internos (web/app/loja/whatsapp), gerando um score de prontidÃ£o (0-100).

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um sistema de scoring que:
- Analisa eventos anÃ´nimos de mÃºltiplos canais (web, app, loja, WhatsApp)
- Calcula features de engajamento (recÃªncia, frequÃªncia, intenÃ§Ã£o, diversidade)
- Gera um score "Ready-to-Reform" de 0-100
- Classifica usuÃ¡rios em: **MOMENTO IDEAL** (â‰¥70), **NUTRIR** (40-69), **NÃƒO ABORDAR** (<40)
- Fornece API REST para consulta de scores
- Dashboard interativo para visualizaÃ§Ã£o
- Job automatizado via GitHub Actions

**âœ… 100% LGPD-safe**: NÃ£o utiliza dados pessoais (sem nome, CPF, telefone, endereÃ§o). Apenas identificadores anÃ´nimos e eventos comportamentais.

## ğŸ—ï¸ Arquitetura

```
reformas-momento-ideal/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample/                 # Dados fake para demo
â”‚       â””â”€â”€ events_sample.csv
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ bigquery_events.sql     # DDL BigQuery
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ event_schema.py         # Schemas de eventos
â”‚   â”œâ”€â”€ features.py             # Feature engineering
â”‚   â”œâ”€â”€ scoring.py              # CÃ¡lculo de scores
â”‚   â”œâ”€â”€ bq_io.py               # I/O BigQuery
â”‚   â”œâ”€â”€ generate_sample_data.py # Gerador de dados fake
â”‚   â””â”€â”€ run_daily_score.py     # Job batch diÃ¡rio
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app.py                 # FastAPI
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ streamlit_app.py       # Dashboard Streamlit
â””â”€â”€ .github/workflows/
    â””â”€â”€ daily_score.yml        # GitHub Actions

```

## ğŸš€ Stack TecnolÃ³gica

- **BigQuery**: Data lake para eventos e scores
- **Python 3.10+**: Processamento e feature engineering
- **FastAPI**: API REST para consulta de scores
- **Streamlit**: Dashboard interativo
- **GitHub Actions**: AutomaÃ§Ã£o do job diÃ¡rio
- **Pandas/NumPy**: ManipulaÃ§Ã£o de dados

## ğŸ“Š Schema BigQuery

### Tabela `events`
```sql
- event_time: TIMESTAMP (quando o evento ocorreu)
- channel: STRING (web|app|store|whatsapp)
- anon_id: STRING (identificador anÃ´nimo)
- event_name: STRING (nome do evento)
- event_props: STRING (JSON com propriedades)
- ingestion_time: TIMESTAMP
```

Particionada por `DATE(event_time)` e clusterizada por `(anon_id, event_name)`.

### Tabela `scores_ready`
```sql
- anon_id: STRING
- score: FLOAT64 (0-100)
- class_label: STRING (MOMENTO IDEAL|NUTRIR|NÃƒO ABORDAR)
- score_date: DATE
- top_drivers: STRING (JSON com top 3 componentes)
- created_at: TIMESTAMP
```

## ğŸ”§ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/henriquefmoura/Modelo-preditivo.git
cd Modelo-preditivo
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. (Opcional) Configure BigQuery

Se for usar BigQuery em produÃ§Ã£o:

```bash
# Defina as variÃ¡veis de ambiente
export BQ_PROJECT_ID="seu-projeto-gcp"
export BQ_DATASET="reformas"
export BQ_CREDENTIALS_JSON="/caminho/para/credentials.json"
```

### 4. Crie as tabelas no BigQuery

```bash
# Execute o SQL no BigQuery Console ou via bq CLI
bq query --use_legacy_sql=false < sql/bigquery_events.sql
```

## ğŸ’» Uso

### Modo Local (com dados de exemplo)

#### 1. Gerar dados de exemplo

```bash
python src/generate_sample_data.py
```

Isso criarÃ¡ `data/sample/events_sample.csv` com 100 usuÃ¡rios e 30 dias de eventos fake.

#### 2. Executar o job de scoring

```bash
python src/run_daily_score.py --local_sample
```

Output:
- Scores salvos em `data/processed/scores_YYYYMMDD.csv`
- Console mostra: total de eventos, usuÃ¡rios, distribuiÃ§Ã£o de classes, top 5 scores

#### 3. Iniciar a API

```bash
uvicorn api.app:app --reload
```

Acesse:
- **API**: http://localhost:8000
- **Docs**: http://localhost:8000/docs

Exemplo de request:
```bash
curl -X POST "http://localhost:8000/score" \
  -H "Content-Type: application/json" \
  -d '{"use_sample": true}'
```

#### 4. Iniciar o Dashboard

```bash
streamlit run dashboard/streamlit_app.py
```

Acesse: http://localhost:8501

### Modo ProduÃ§Ã£o (com BigQuery)

#### 1. Configure as credenciais

```bash
export BQ_PROJECT_ID="seu-projeto"
export BQ_DATASET="reformas"
export BQ_CREDENTIALS_JSON="/path/to/credentials.json"
```

#### 2. Execute o job

```bash
python src/run_daily_score.py --lookback_days 30
```

#### 3. API com BigQuery

A API automaticamente detecta as credenciais do BigQuery e permite consultas:

```bash
curl -X POST "http://localhost:8000/score" \
  -H "Content-Type: application/json" \
  -d '{"anon_ids": ["anon_00001", "anon_00002"]}'
```

## ğŸ“ˆ Features Calculadas

O sistema calcula as seguintes features por `anon_id`:

1. **recency_days**: Dias desde o Ãºltimo evento relevante
2. **freq_7d, freq_14d, freq_30d**: FrequÃªncia de eventos em janelas de tempo
3. **high_intent_7d**: Eventos de alta intenÃ§Ã£o nos Ãºltimos 7 dias
   - submit_quote, whatsapp_quote_request, scan_qr_service, talk_to_consultant, begin_checkout
4. **category_diversity_14d**: NÃºmero de categorias distintas acessadas
5. **cart_abandon_7d**: Carrinhos abandonados (add_to_cart sem begin_checkout em 24h)
6. **reform_bundle_14d**: Detecta combos tÃ­picos de reforma:
   - piso + rodapÃ©
   - tinta + massa + lixa
   - azulejo + rejunte
   - porta + fechadura
   - janela + persiana

## ğŸ¯ Score Ready-to-Reform

Score de 0-100 calculado com pesos ajustÃ¡veis:

- **30%** RecÃªncia (mais recente = maior score)
- **25%** High Intent (eventos de alta intenÃ§Ã£o)
- **20%** FrequÃªncia (mais engajamento = maior score)
- **15%** Diversidade de categorias
- **10%** Bundles + Abandono de carrinho

### ClassificaÃ§Ã£o

- **â‰¥70**: **MOMENTO IDEAL** - Abordar agora
- **40-69**: **NUTRIR** - Continuar engajamento
- **<40**: **NÃƒO ABORDAR** - Baixo potencial no momento

## ğŸ¤– GitHub Actions

O workflow `daily_score.yml` executa automaticamente Ã s 06:00 UTC todos os dias.

### Configurar Secrets

No GitHub, vÃ¡ em `Settings > Secrets and variables > Actions` e adicione:

- `BQ_PROJECT_ID`: ID do projeto Google Cloud
- `BQ_DATASET`: Nome do dataset (padrÃ£o: "reformas")
- `BQ_CREDENTIALS_JSON`: ConteÃºdo do arquivo JSON de credenciais

### Executar manualmente

No GitHub: `Actions > Daily Ready-to-Reform Scoring > Run workflow`

## ğŸ“– API Endpoints

### `GET /`
InformaÃ§Ãµes da API

### `GET /health`
Health check

### `POST /score`
Calcula scores

**Request body:**
```json
{
  "use_sample": true  // Usar dados de exemplo
}
```

ou

```json
{
  "anon_ids": ["anon_00001", "anon_00002"]  // Buscar do BigQuery
}
```

ou

```json
{
  "events": [
    {
      "event_time": "2024-01-15T10:30:00",
      "channel": "web",
      "anon_id": "anon_12345",
      "event_name": "submit_quote",
      "event_props": {"category": "piso", "value": 1500.0}
    }
  ]
}
```

**Response:**
```json
{
  "scores": [
    {
      "anon_id": "anon_00001",
      "score": 75.5,
      "class_label": "MOMENTO IDEAL",
      "top_drivers": {
        "recency": 30.0,
        "high_intent": 25.0,
        "frequency": 20.5
      }
    }
  ],
  "count": 1,
  "timestamp": "2024-01-15T10:30:00"
}
```

## ğŸ“Š Dashboard

O dashboard Streamlit oferece:

- ğŸ“ˆ **DistribuiÃ§Ã£o por classe**: GrÃ¡fico de pizza com % de cada classificaÃ§Ã£o
- ğŸ† **Ranking**: Top 50 usuÃ¡rios por score
- ğŸ¯ **Score drivers**: Componentes que mais contribuem para o score
- ğŸ” **Filtros**: Por classificaÃ§Ã£o, range de score
- ğŸ“Š **Histograma**: DistribuiÃ§Ã£o dos scores

## ğŸ§ª Testes

Para testar o sistema completo em modo local:

```bash
# 1. Gerar dados
python src/generate_sample_data.py

# 2. Rodar scoring
python src/run_daily_score.py --local_sample

# 3. Testar API
uvicorn api.app:app --reload &
curl http://localhost:8000/health

# 4. Testar dashboard
streamlit run dashboard/streamlit_app.py
```

## ğŸ”’ SeguranÃ§a e LGPD

âœ… **Totalmente anÃ´nimo**: Nenhum dado pessoal Ã© coletado ou armazenado
- âŒ Sem nome
- âŒ Sem CPF
- âŒ Sem telefone
- âŒ Sem e-mail
- âŒ Sem endereÃ§o
- âœ… Apenas `anon_id` (hash/cookie/token)

## ğŸ“ LicenÃ§a

Este projeto Ã© parte de uma tese de doutorado.

## ğŸ‘¨â€ğŸ’» Autor

Henrique F. Moura
